# Job Search Agent Implementation Plan

## Goal
Build a React-based agent that orchestrates the job search process:
1.  Collects user preferences (Role, Country).
2.  Parses uploaded resumes.
3.  Searches for *new* jobs via SerpAPI.
4.  Filters/Matches jobs using AI analysis of the resume vs. job description.
5.  Outputs matches in a structured table.

## User Interface Design (Frontend)
-   **Style**: Aesthetically beautiful, modern, clean, **no gradient coloring**.
-   **Metaphor**: Conversational UI (Chat) mixed with Structured Views (Dashboard/Table).
-   **Tech Stack**: React (Vite), TypeScript, Tailwind CSS, Lucide React (Icons), ShadcnUI (optional, but recommended for premium feel).

## Backend Architecture
-   **Tech Stack**: Python (FastAPI).
-   **AI Core**: OpenAI API (GPT-4o or similar).
-   **Reasoning**: Python is the lingua franca for AI agents. We will use OpenAI for resume analysis, job matching, and generating justifications.
-   **Storage**: **SQLite database** for search history persistence (stores searches, matched jobs, resume hashes).
-   **Configuration**: All API keys and System Prompts must be in `.env`.

## Architecture & Work Split
We will separate the repository into two distinct directories: `frontend/` and `backend/`. This allows two agents to work completely independently, synchronized by a clear API contract.

### Directory Structure
```
/
├── frontend/         # React Application
├── backend/          # FastAPI Application
├── agent.md          # Instructions for Agents
└── README.md
```

## Detailed Implementation Plan

### Phase 1: Setup & Environment (Architect - DONE)
- [x] Analyze requirements and select stack.
- [x] Create project skeleton.
- [x] Define API contract.

### Phase 2: Frontend Agent
**Objective**: Build the visual interface and state management.
**Instructions**:
1.  Initialize a Vite React TS project in `frontend/`.
2.  Implement a modern Chat Interface.
    *   Message bubbles (User vs Agent).
    *   Input field (Text).
    *   File Upload component (Drag & drop).
3.  Implement the "Results Table" component.
    *   Columns: Role Title, Company, Match Score, **Match Justification** (Why LLM thinks this is a fit), Action (Apply Link).
    *   Design: Clean, readable text for the justification.
4.  Integrate with Backend API (mock first if needed).
5.  **Design Rules**:
    *   Use solid colors (slate, white, black, primary blue/indigo). NO GRADIENTS.
    *   Clean typography (Inter or Roboto).
    *   Generous whitespace.

### Phase 3: Backend Agent
**Objective**: Build the intelligence and API endpoints.
**Instructions**:
1.  Initialize a Python environment in `backend/` with `fastapi`, `uvicorn`, `python-multipart`, `pypdf`, `openai`, `google-search-results`.
2.  **Configuration**: Create `.env` file reading:
    *   `OPENAI_API_KEY`
    *   `SERPAPI_API_KEY`
    *   `SYSTEM_PROMPT`: "You are a helpful job search assistant..." (Allow user to edit this).
3.  Implement `POST /chat/init`: returns initial greeting generated by LLM (using System Prompt).
4.  Implement `POST /parse-resume`: Accepts PDF/Docx, extracts text using `pypdf`.
5.  Implement `POST /search-jobs`: Accepts `{ roles, country, resume_text }`.
    *   Step A: Call SerpApi for "jobs in [Country] for [Roles]" with `date_posted: today`.
    *   Step B: (Parallelized) For each job, call **OpenAI** to compare `job_description` vs `resume_text`.
    *   Step C: **Critical**: The LLM must generate a "Justification" string explaining the strong match.
    *   Step D: Return filtered list with columns: Role, Company, Link, Score, Justification.

## Validation Questions & FAQ
1.  **Why React + Python?**
    *   React provides the most responsive and customizable UI. Python is best for the heavy lifting of text analysis and search integration.
2.  **How do agents communicate?**
    *   REST API (JSON). FE polls or simply awaits async responses.
3.  **Key Challenges?**
    *   *Latency*: Analyzing 10-20 job descriptions with an LLM can take time.
    *   *Solution*: The Backend should maybe stream results or provide a progress update (SSE - Server Sent Events) if possible, or just a simple loading state for MVP.

## Implemented Features

### Search History Database (SQLite)
- **Location**: `backend/database/searches.db`
- **Tables**:
  - `searches`: Stores query, location, timestamp
  - `jobs`: Stores matched jobs with score, justification, link
  - `resume_texts`: Stores resume hash for deduplication
- **API Endpoint**: `GET /search-history` - Returns last 10 searches with job counts
- **Frontend Integration**: Sidebar displays real search history dynamically

### Job URL Fix
- **Issue**: Links were pointing to Google Jobs search page instead of specific job postings
- **Solution**: Priority-based URL extraction:
  1. `apply_link` (Direct application link - best)
  2. `related_links[0]` (Original job posting site)
  3. `share_link` (Fallback - Google Jobs search)
- **Result**: "Apply" buttons now open specific job postings on LinkedIn, company sites, etc.

### UI Enhancements
- **Design**: Anthropic Claude-inspired warm dark theme
- **Typography**: Merriweather (serif) + Inter (sans-serif)
- **Color Palette**: Terracotta accent (#D97757) with warm blacks
- **Visual Effects**: Glowing avatars, gradient backgrounds, smooth transitions

